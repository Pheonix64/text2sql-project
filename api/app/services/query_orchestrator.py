# query_orchestrator.py
"""
QueryOrchestrator (LangChain-first, production-ready)
- Charge sch√©ma enrichi depuis PostgreSQL (comments)
- Indexe des exemples question<->SQL depuis examples.json vers Chroma
- Pipeline: similarity -> SQL generation (LLM) -> validate -> execute -> NL analysis (LLM)
- Gestion stricte des s√©maphores et appels async-safe
- Contient stubs/fonctions compl√®tes pour forecasting/interpretation d'inflation
"""

from __future__ import annotations
import re
import json
import asyncio
import textwrap
import uuid
from typing import Any, Dict, List, Optional, Tuple
from logging import getLogger
import datetime
import sqlglot
from sqlalchemy import create_engine, text, exc
from datetime import datetime


# LangChain components
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableLambda
from langchain_core.output_parsers import StrOutputParser
from langchain_ollama import ChatOllama
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_community.utilities import SQLDatabase

# Chroma direct client & Ollama direct client (for pull)
import chromadb
import ollama

# Replace with your app config module
from app.config import settings

logger = getLogger(__name__)


DEFAULT_EXAMPLES_PATH = "/home/appuser/docs/examples.json"


class QueryOrchestrator:
    def __init__(self, db_tables: Optional[List[str]] = None, examples_path: str = DEFAULT_EXAMPLES_PATH):
        logger.info("Initialisation de QueryOrchestrator...")
        # ---------------- resources & semaphores ----------------
        self.embed_sem = asyncio.Semaphore(2)
        self.chroma_sem = asyncio.Semaphore(4)
        self.llm_sem = asyncio.Semaphore(2)

        # ---------------- embeddings & vector store -------------
        self.embedding_model = HuggingFaceEmbeddings(
            model_name=settings.EMBEDDING_MODEL_NAME,
            encode_kwargs={"normalize_embeddings": False},
        )
        self.chroma_client = chromadb.HttpClient(host=settings.CHROMA_HOST, port=settings.CHROMA_PORT)
        self.sql_collection = self.chroma_client.get_or_create_collection(name=settings.CHROMA_COLLECTION)
        self.vector_store = Chroma(
            client=self.chroma_client,
            collection_name=settings.CHROMA_COLLECTION,
            embedding_function=self.embedding_model,
        )

        # ---------------- LLM & ollama client -------------------
        self.llm = ChatOllama(model=settings.LLM_MODEL, base_url=settings.OLLAMA_BASE_URL)
        self.ollama_client = ollama.AsyncClient(host=settings.OLLAMA_BASE_URL)

        # ---------------- DB engines ---------------------------
        try:
            self.db_engine = create_engine(
                settings.DATABASE_URL,
                pool_size=10,
                max_overflow=20,
                pool_pre_ping=True,
            )
            self.admin_db_engine = create_engine(settings.ADMIN_DATABASE_URL)
        except Exception as e:
            logger.error("Erreur cr√©ation engines DB: %s", e)
            raise

        # allow multiple tables
        self.db_tables = db_tables or ["indicateurs_economiques_uemoa"]

        try:
            self.langchain_db = SQLDatabase(engine=self.db_engine, include_tables=self.db_tables)
        except Exception as e:
            logger.warning("Impossible d'initialiser SQLDatabase: %s", e)
            self.langchain_db = None

        # examples file path
        self.examples_path = examples_path

        # schema will be charg√© par initialize_context
        self.db_schema: str = ""

        # prompt templates centralis√©s
        self.sql_generation_template = PromptTemplate(
            input_variables=["db_schema", "context_queries", "user_question", "chat_history", "correction_instruction"],
            template=self._sql_generation_template_text(),
        )
        self.natural_language_template = PromptTemplate(
            input_variables=["user_question", "sql_result_str"],
            template=self._natural_language_template_text(),
        )

        # runnables built later
        self._build_runnables()

        # reference example queries (backup)
        self.reference_queries = [
            "SELECT pib_nominal_milliards_fcfa FROM indicateurs_economiques_uemoa WHERE date = '2022-01-01';",
            "SELECT date, exportations_biens_fob, importations_biens_fob, balance_des_biens FROM indicateurs_economiques_uemoa WHERE EXTRACT(YEAR FROM date) = 2021;",
            "SELECT AVG(taux_croissance_reel_pib_pct) FROM indicateurs_economiques_uemoa WHERE date >= '2015-01-01' AND date <= '2020-12-31';",
        ]

        # init keyword sets
        self._init_keyword_sets()

        # Conversational memory for Text-to-SQL
        self.conversations: Dict[str, List[Dict[str, str]]] = {}
        
        # Conversational memory for Inflation Interpretation
        # Stores: {conversation_id: {"last_interpretation": {...}, "questions": [...]}}
        self.inflation_conversations: Dict[str, Dict[str, Any]] = {}

        logger.info("QueryOrchestrator initialis√©.")

    # ------------------------ Initialization helpers -------------------------
    async def initialize_context(self, index_examples: bool = True, examples_list: Optional[List[Dict[str, str]]] = None):
        """
        Charge le sch√©ma enrichi depuis la base et indexe les exemples (si demand√©).
        Appeler au d√©marrage du service pour pr√©parer les prompts/contextes.
        """
        logger.info("Chargement du sch√©ma enrichi depuis la base...")
        self.db_schema = self._get_rich_db_schema_for_tables(self.db_tables)

        # si on souhaite indexer : charger depuis examples.json ou utiliser examples_list
        if index_examples:
            if examples_list:
                examples = examples_list
            else:
                examples = self._load_or_create_examples_file(self.examples_path)
            # indexe dans Chroma (embedding batch)
            try:
                self.index_reference_queries(examples)
            except Exception as e:
                logger.warning("Indexation des exemples √©chou√©e: %s", e)

    def _load_or_create_examples_file(self, path: str) -> List[Dict[str, str]]:
        """Charge examples.json si pr√©sent, sinon cr√©e un fichier avec exemples par d√©faut et le retourne."""
        default_examples = [
            {
                "question": "Quel est le taux de croissance r√©el du PIB de l'UEMOA pour l'ann√©e 2022 ?",
                "sql": "SELECT date, taux_croissance_reel_pib_pct FROM indicateurs_economiques_uemoa WHERE date = '2022-01-01';"
            },
            {
                "question": "Quelle a √©t√© l'inflation moyenne annuelle entre 2015 et 2020 ?",
                "sql": "SELECT AVG(taux_inflation_moyen_annuel_ipc_pct) AS avg_inflation FROM indicateurs_economiques_uemoa WHERE date BETWEEN '2015-01-01' AND '2020-12-31';"
            },
            {
                "question": "Liste des 5 derni√®res ann√©es du PIB nominal (en milliards FCFA).",
                "sql": "SELECT date, pib_nominal_milliards_fcfa FROM indicateurs_economiques_uemoa ORDER BY date DESC LIMIT 5;"
            },
            {
                "question": "Encours de la dette en % du PIB pour 2020 et 2021.",
                "sql": "SELECT date, encours_de_la_dette_pct_pib FROM indicateurs_economiques_uemoa WHERE date IN ('2020-01-01', '2021-01-01') ORDER BY date;"
            },
            {
                "question": "Balance commerciale (export - import) pour 2019.",
                "sql": "SELECT date, balance_des_biens FROM indicateurs_economiques_uemoa WHERE date = '2019-01-01';"
            },
            {
                "question": "Comment l'inflation a-t-elle √©volu√© au cours des 5 derni√®res ann√©es ?",
                "sql": "SELECT date, taux_inflation_moyen_annuel_ipc_pct FROM indicateurs_economiques_uemoa ORDER BY date DESC LIMIT 5;"
            },
            {
                "question": "√âvolution du taux d'inflation entre 2018 et 2023.",
                "sql": "SELECT date, taux_inflation_moyen_annuel_ipc_pct FROM indicateurs_economiques_uemoa WHERE EXTRACT(YEAR FROM date) BETWEEN 2018 AND 2023 ORDER BY date;"
            },
            {
                "question": "Quel est le taux d'inflation en glissement annuel pour 2022 ?",
                "sql": "SELECT date, taux_inflation_glissement_annuel_pct FROM indicateurs_economiques_uemoa WHERE EXTRACT(YEAR FROM date) = 2022;"
            },
            {
                "question": "√âvolution du PIB nominal de 2018 √† 2024.",
                "sql": "SELECT date, pib_nominal_milliards_fcfa FROM indicateurs_economiques_uemoa WHERE EXTRACT(YEAR FROM date) BETWEEN 2018 AND 2024 ORDER BY date;"
            },
            {
                "question": "Quelle est la masse mon√©taire M2 en 2021 ?",
                "sql": "SELECT date, agregats_monnaie_masse_monetaire_m2 FROM indicateurs_economiques_uemoa WHERE EXTRACT(YEAR FROM date) = 2021;"
            },
            {
                "question": "Quelle est la progression du PIB entre 2020 et 2024 ?",
                "sql": "SELECT date, pib_nominal_milliards_fcfa FROM indicateurs_economiques_uemoa WHERE EXTRACT(YEAR FROM date) BETWEEN 2020 AND 2024 ORDER BY date;"
            },
            {
                "question": "Quel est le taux de croissance moyen du PIB sur les 5 derni√®res ann√©es ?",
                "sql": "SELECT AVG(taux_croissance_reel_pib_pct) AS croissance_moyenne FROM indicateurs_economiques_uemoa ORDER BY date DESC LIMIT 5;"
            },
            {
                "question": "Compare le PIB de 2020 et 2024.",
                "sql": "SELECT date, pib_nominal_milliards_fcfa FROM indicateurs_economiques_uemoa WHERE EXTRACT(YEAR FROM date) IN (2020, 2024) ORDER BY date;"
            },
        ]
        try:
            with open(path, "r", encoding="utf-8") as f:
                examples = json.load(f)
                logger.info("Charg√© %d exemples depuis %s", len(examples), path)
                return examples
        except FileNotFoundError:
            with open(path, "w", encoding="utf-8") as f:
                json.dump(default_examples, f, ensure_ascii=False, indent=2)
            logger.info("Fichier d'exemples non trouv√©. Cr√©ation de %s avec exemples par d√©faut.", path)
            return default_examples
        except Exception as e:
            logger.warning("Impossible de charger/√©crire %s: %s. Retour d'exemples par d√©faut.", path, e)
            return default_examples

    # ------------------------ Prompt templates -------------------------------
    def _sql_generation_template_text(self) -> str:
        return textwrap.dedent(
            """\
            ### Instruction (g√©n√©ration SQL avec raisonnement)
            Tu es un expert SQL (PostgreSQL) et analyste √©conomique sp√©cialis√© en politique mon√©taire de l'UEMOA.
            
            **√âTAPE 1 - RAISONNEMENT (Chain of Thought)**
            Avant de g√©n√©rer le SQL, analyse la question √©tape par √©tape :
            1. Quelles informations sont demand√©es ? (indicateur, p√©riode, agr√©gation...)
            2. Quelles colonnes du sch√©ma correspondent √† ces informations ?
            3. Quelle logique SQL appliquer ? (filtrage, agr√©gation, tri, calcul...)
            
            √âcris ton raisonnement entre les balises <raisonnement> et </raisonnement>.
            
            **√âTAPE 2 - G√âN√âRATION SQL**
            Apr√®s le raisonnement, g√©n√®re la requ√™te SQL entre les balises <sql> et </sql>.

            ‚ö†Ô∏è CONTRAINTES CRITIQUES ‚ö†Ô∏è
            1. N'INVENTE JAMAIS de noms de colonnes ! Utilise UNIQUEMENT les colonnes list√©es dans le sch√©ma ci-dessous.
            2. Pour l'inflation, la colonne s'appelle : taux_inflation_moyen_annuel_ipc_pct (PAS "taux_inflation_pct" ni "inflation")
            3. Pour le PIB, la colonne s'appelle : pib_nominal_milliards_fcfa
            4. Pour la croissance, la colonne s'appelle : taux_croissance_reel_pib_pct
            5. Les donn√©es sont annuelles avec une date au format 'YYYY-01-01' (ex: '2022-01-01' pour l'ann√©e 2022)
            6. Pour filtrer par ann√©e, utilise : EXTRACT(YEAR FROM date) = 2022 ou date = '2022-01-01'
            7. Ne g√©n√®re JAMAIS d'instruction de modification (INSERT/UPDATE/DELETE/DROP...)
            
            üìä R√àGLE D'OR : VALEURS EXACTES üìä
            - Retourne TOUJOURS les valeurs exactes de la base de donn√©es (date + valeur).
            - PRIVIL√âGIE les requ√™tes simples qui retournent les donn√©es brutes plut√¥t que des calculs complexes.
            - Pour une √©volution/progression, retourne simplement les valeurs ann√©e par ann√©e avec ORDER BY date.
            - L'analyse et les calculs seront faits par l'assistant, pas par SQL.
            
            ‚ö†Ô∏è SYNTAXE SQL INTERDITE ‚ö†Ô∏è
            - JAMAIS de syntaxe comme colonne[condition] (ex: pib[annee=2024] est INVALIDE)
            - JAMAIS de r√©f√©rences de tableau avec crochets []
            - Pour comparer des valeurs entre ann√©es, utilise :
              * Soit une simple requ√™te avec WHERE et ORDER BY
              * Soit LAG/LEAD pour les variations
              * Soit des sous-requ√™tes s√©par√©es
            
            Exemple CORRECT pour progression entre 2020 et 2024 :
            SELECT date, pib_nominal_milliards_fcfa FROM indicateurs_economiques_uemoa WHERE EXTRACT(YEAR FROM date) IN (2020, 2024) ORDER BY date;

            ### Sch√©ma de la base de donn√©es (COLONNES DISPONIBLES)
            {db_schema}

            ### Exemples de requ√™tes similaires (COPIE les noms de colonnes de ces exemples)
            {context_queries}

            ### Historique de la conversation
            {chat_history}

            ### Question de l'utilisateur
            "{user_question}"

            ### Instruction de correction (si applicable)
            {correction_instruction}

            ### R√©ponse (raisonnement puis SQL entre balises)
            """
        )

    def _natural_language_template_text(self) -> str:
        return textwrap.dedent(
            """
                Tu es un analyste √©conomique expert √† la BCEAO. En te basant SEULEMENT sur la QUESTION de l'utilisateur et EXCLUSIVEMENT sur le R√âSULTAT SQL fourni, r√©dige une analyse synth√©tique, claire et rationnelle en fran√ßais.

                Toutes les donn√©es concernent l'ensemble de l'Union (BCEAO) sauf mention explicite de 'country'. Ne jamais inventer de chiffres hors du r√©sultat SQL.

                ‚ö†Ô∏è CAS PARTICULIERS √Ä G√âRER ‚ö†Ô∏è
                
                1. Si le R√âSULTAT SQL est vide, ne contient que "[]" ou ne retourne aucune ligne :
                   ‚Üí R√©ponds EXACTEMENT : "Les donn√©es demand√©es ne sont pas disponibles dans notre base pour la p√©riode ou l'indicateur sp√©cifi√©. Notre base couvre les indicateurs macro√©conomiques de l'UEMOA de 2005 √† 2024. Pourriez-vous v√©rifier la p√©riode ou l'indicateur demand√© ?"
                   ‚Üí Ne jamais inventer de chiffres dans ce cas.
                
                2. Si la question de l'utilisateur est ambigu√´, trop vague, hors sujet √©conomique, ou incompr√©hensible :
                   ‚Üí R√©ponds EXACTEMENT : "Votre question n√©cessite des pr√©cisions pour que je puisse vous fournir une analyse pertinente. Pourriez-vous reformuler en pr√©cisant :
                   - L'indicateur √©conomique souhait√© (PIB, inflation, dette, balance commerciale, etc.)
                   - La p√©riode concern√©e (ann√©e ou plage d'ann√©es entre 2005 et 2024)
                   - Le pays ou si c'est pour l'ensemble de l'UEMOA
                   - Le type d'analyse attendu (valeur, √©volution, comparaison, moyenne, etc.)"
                
                3. Si les donn√©es sont partielles (certaines ann√©es demand√©es absentes du r√©sultat) :
                   ‚Üí Mentionne explicitement les ann√©es pour lesquelles les donn√©es sont disponibles.
                   ‚Üí Indique les ann√©es manquantes si pertinent.

                R√àGLES POUR LA R√âPONSE (si des donn√©es sont disponibles) :
                - Commencer par 3 √† 4 phrases r√©sumant l'information principale.
                - Donner le contexte et la port√©e.
                - Pr√©senter les chiffres cl√©s issus du r√©sultat SQL (langage pour communiquer avec une base de donn√©es).
                - Proposer une interpr√©tation raisonn√©e.
                - Expliquer bri√®vement la m√©thodologie et/ou les colonnes utilis√©es.
                - Mentionner les limites et/ou hypoth√®ses √©ventuelles.
                - Se terminer par 2 √† 4 recommandations pratiques.
                - Ne jamais divulguer la requ√™te SQL ni le r√©sultat brut.
                - Ne jamais inventer de donn√©es ni extrapoler au-del√† du r√©sultat SQL.
                - Ne jamais faire des r√©p√©titions inutiles.
                - Tout ce qui est un montant doit √™tre en chiffres exacts avec unit√©s (FCFA) (ex: 1234.56 milliards FCFA).
                - Le PIB est toujours en milliards FCFA.

                La r√©ponse doit √™tre r√©dig√©e comme un rapport synth√©tique fluide, destin√© √† un d√©cideur, et ne jamais contenir de titres ou sous-titres visibles.

                ### Question
                {user_question}

                ### R√©sultat SQL
                {sql_result_str}

                ### R√©ponse
                """
                        )

    # ------------------------ Runnables builders --------------------------------
    def _build_runnables(self):
        # Runnable to generate SQL (async)
        async def _run_sql_generation(inputs: Dict[str, Any]) -> Dict[str, Any]:
            prompt = self.sql_generation_template.format(
                db_schema=inputs.get("db_schema", self.db_schema),
                context_queries=inputs.get("context_queries", ""),
                user_question=inputs.get("user_question", ""),
                chat_history=inputs.get("chat_history", ""),
                correction_instruction=inputs.get("correction_instruction", ""),
            )
            llm_text = await self._call_llm(prompt)
            sql = self._extract_sql_from_text(llm_text)
            reasoning = self._extract_reasoning_from_text(llm_text)
            if reasoning:
                logger.info(f"Raisonnement LLM: {reasoning[:200]}...")  # Log les 200 premiers caract√®res
            return {"generated_sql": sql, "llm_text": llm_text, "reasoning": reasoning}

        # Runnable to validate/execute and produce final answer
        async def _run_response_generation(inputs: Dict[str, Any]) -> Dict[str, Any]:
            generated_sql = inputs.get("generated_sql", "")
            user_question = inputs.get("user_question", "")
            # Si le r√©sultat est d√©j√† fourni (par la boucle de retry), on l'utilise
            sql_result = inputs.get("sql_result")

            if sql_result is None:
                # validate
                if not generated_sql or not re.search(r"^\s*(SELECT|WITH)\b", generated_sql, flags=re.IGNORECASE):
                    raise ValueError("Aucune requ√™te SELECT/WITH g√©n√©r√©e.")
                if not self._validate_sql(generated_sql):
                    raise ValueError("La requ√™te SQL g√©n√©r√©e a √©t√© jug√©e non s√©curis√©e.")

                # execute
                sql_result = await self._validate_and_execute_sql(generated_sql)
            
            sql_result_str = str(sql_result)

            # NL prompt
            nl_prompt = self.natural_language_template.format(
                user_question=user_question,
                sql_result_str=sql_result_str
            )
            final_text = await self._call_llm(nl_prompt)
            return {"final_answer": final_text, "sql_result": sql_result}

        self.sql_generation_runnable = RunnableLambda(_run_sql_generation)
        self.response_generation_runnable = RunnableLambda(_run_response_generation)

    # ------------------------ Core LLM / similarity / SQL helpers ----------------
    async def _call_llm(self, prompt: str, timeout: int = 90) -> str:
        """Appel LLM avec s√©maphore, fallback pull_model si mod√®le absent."""
        try:
            async with self.llm_sem:
                res = await asyncio.wait_for(self.llm.ainvoke(prompt), timeout=timeout)
            return res.content if hasattr(res, "content") else str(res)
        except Exception as e:
            msg = str(e).lower()
            logger.warning("LLM call error: %s", e)
            if "not found" in msg or "404" in msg:
                logger.info("LLM model not found, attempting to pull...")
                pull_res = await self.pull_model()
                if pull_res.get("status") == "success":
                    async with self.llm_sem:
                        res = await asyncio.wait_for(self.llm.ainvoke(prompt), timeout=timeout)
                    return res.content if hasattr(res, "content") else str(res)
            raise

    async def _similarity_search(self, question: str, k: int = 5) -> List[str]:
        async with self.chroma_sem:
            docs = await asyncio.to_thread(self.vector_store.similarity_search, question, k)
        return [getattr(d, "page_content", str(d)) for d in docs]

    async def _validate_and_execute_sql(self, sql: str) -> List[Dict[str, Any]]:
        if not sql or not self._validate_sql(sql):
            raise ValueError("La requ√™te SQL g√©n√©r√©e est invalide ou non s√©curis√©e.")
        return await self._execute_sql_readonly(sql)

    # ------------------------ Public pipeline -----------------------------------
    async def process_user_question(self, user_question: str, conversation_id: Optional[str] = None) -> Dict[str, Any]:
        # 0) Ensure conversation_id exists and check history
        if not conversation_id:
            conversation_id = str(uuid.uuid4())
            logger.info(f"G√©n√©ration d'un nouveau conversation_id: {conversation_id}")
        
        has_history = False
        if conversation_id in self.conversations and self.conversations[conversation_id]:
            has_history = True

        # 1) Security and routing
        if self._is_question_harmful(user_question):
            return {"answer": "D√©sol√©, je ne peux pas traiter cette demande.", "conversation_id": conversation_id}
        
        # On passe has_history pour assouplir le filtrage si on est dans une conversation
        if not self._needs_data_retrieval(user_question, has_history=has_history):
            return {"answer": "D√©sol√©, cette question ne concerne pas les donn√©es √©conomiques de l'UEMOA/BCEAO.", "conversation_id": conversation_id}

        # 2) Similarity context
        try:
            similar_docs = await self._similarity_search(user_question, k=5)
            context_queries = "\n".join(similar_docs)
        except Exception as e:
            logger.warning("Similarity search failed: %s", e)
            context_queries = ""

        # 3) Chat History Management
        chat_history_str = ""
        if has_history:
            history = self.conversations.get(conversation_id, [])
            # On garde les 5 derniers √©changes pour le contexte
            recent_history = history[-5:]
            for turn in recent_history:
                chat_history_str += f"User: {turn['user']}\nAssistant: {turn['assistant']}\n"

        # 4) Generate SQL with Retry Loop (Auto-Correction)
        MAX_RETRIES = 3
        correction_instruction = ""
        generated_sql = ""
        sql_result = []
        last_error = None

        for attempt in range(MAX_RETRIES):
            try:
                if attempt > 0:
                    logger.info(f"Tentative de correction SQL {attempt + 1}/{MAX_RETRIES}")
                
                sql_res = await self.sql_generation_runnable.ainvoke({
                    "user_question": user_question,
                    "db_schema": self.db_schema,
                    "context_queries": context_queries,
                    "chat_history": chat_history_str,
                    "correction_instruction": correction_instruction
                })
                generated_sql = sql_res.get("generated_sql", "")

                # 3) Sanity & validate
                if not generated_sql or not re.search(r"^\s*(SELECT|WITH)\b", generated_sql, flags=re.IGNORECASE):
                    raise ValueError("Pas de requ√™te SQL valide g√©n√©r√©e (SELECT/WITH manquant).")

                if not self._validate_sql(generated_sql):
                    raise ValueError("Requ√™te SQL jug√©e non s√©curis√©e par le validateur.")

                # 4) Execute (Try to run the query)
                sql_result = await self._validate_and_execute_sql(generated_sql)
                
                # Si on arrive ici, c'est un succ√®s
                last_error = None
                break

            except Exception as e:
                logger.warning(f"√âchec tentative {attempt + 1}: {e}")
                last_error = e
                # On pr√©pare l'instruction de correction pour la prochaine it√©ration
                # On inclut le sch√©ma pour rappeler les colonnes disponibles
                correction_instruction = (
                    f"‚ö†Ô∏è ERREUR √Ä CORRIGER ‚ö†Ô∏è\n"
                    f"La requ√™te pr√©c√©dente a √©chou√© avec l'erreur suivante :\n"
                    f"```\n{e}\n```\n"
                    f"Requ√™te g√©n√©r√©e (incorrecte) : {generated_sql}\n\n"
                    f"RAPPEL DU SCH√âMA DISPONIBLE:\n{self.db_schema}\n\n"
                    f"Analyse l'erreur et utilise UNIQUEMENT les colonnes list√©es ci-dessus pour corriger la requ√™te."
                )
        
        if last_error:
            return {
                "answer": f"D√©sol√©, je n'ai pas r√©ussi √† g√©n√©rer une requ√™te valide apr√®s {MAX_RETRIES} tentatives. Erreur technique : {last_error}",
                "generated_sql": generated_sql,
                "conversation_id": conversation_id
            }

        # 5) NL generation (using the successful sql_result)
        try:
            response_res = await self.response_generation_runnable.ainvoke({
                "generated_sql": generated_sql,
                "user_question": user_question,
                "sql_result": sql_result  # Pass the result we already got
            })
            final_answer = response_res.get("final_answer", "")
            
            # 6) Update History
            if conversation_id:
                if conversation_id not in self.conversations:
                    self.conversations[conversation_id] = []
                self.conversations[conversation_id].append({
                    "user": user_question,
                    "assistant": final_answer
                })

        except Exception as e:
            logger.error("Erreur pendant g√©n√©ration r√©ponse finale: %s", e)
            return {"answer": "Une erreur est survenue lors de la formulation de la r√©ponse.", "generated_sql": generated_sql, "conversation_id": conversation_id}

        return {"answer": final_answer, "generated_sql": generated_sql, "sql_result": str(sql_result), "conversation_id": conversation_id}

    # ------------------------ Indexing / examples --------------------------------
    def index_reference_queries(self, examples: Optional[List[Dict[str, str]]] = None) -> int:
        """
        Indexe exemples (list[{"question":..,"sql":..}]) dans Chroma.
        Si None, indexe self.reference_queries (simple list of SQL).
        """
        if examples is None:
            examples = [{"question": None, "sql": q} for q in self.reference_queries]

        # prepare documents: combine question + sql to help retrieval
        docs = []
        for i, ex in enumerate(examples):
            content = f"Question: {ex.get('question') or ''}\nRequ√™te SQL: {ex.get('sql')}"
            docs.append({"id": f"ex_{i}", "content": content})

        # embed & add via chroma client for determinism
        embeddings = self.embedding_model.embed_documents([d["content"] for d in docs])
        # ensure we clear previous
        if self.sql_collection.count() > 0:
            ids_to_delete = self.sql_collection.get().get("ids") or []
            if ids_to_delete and isinstance(ids_to_delete[0], list):
                ids_to_delete = [i for sub in ids_to_delete for i in sub]
            if ids_to_delete:
                self.sql_collection.delete(ids=ids_to_delete)
        self.sql_collection.add(
            embeddings=embeddings,
            documents=[d["content"] for d in docs],
            ids=[d["id"] for d in docs],
        )
        logger.info("Indexation termin√©e (%d exemples).", len(docs))
        return len(docs)

    # ------------------------ DB schema extraction -------------------------------
    def _get_rich_db_schema_for_tables(self, table_names: List[str]) -> str:
        pieces = []
        for table in table_names:
            pieces.append(self._get_rich_db_schema(table))
        return "\n\n".join(pieces)

    def _get_rich_db_schema(self, table_name: str) -> str:
        """Lit information_schema + pg_description pour retourner un CREATE TABLE comment√©."""
        query = text("""
            SELECT
                c.column_name,
                c.data_type,
                pgd.description
            FROM information_schema.columns AS c
            LEFT JOIN
                pg_catalog.pg_statio_all_tables AS st ON c.table_schema = st.schemaname AND c.table_name = st.relname
            LEFT JOIN
                pg_catalog.pg_description AS pgd ON pgd.objoid = st.relid AND pgd.objsubid = c.ordinal_position
            WHERE c.table_name = :table_name
            ORDER BY c.ordinal_position;
        """)
        table_comment_query = text(f"SELECT obj_description('public.{table_name}'::regclass);")
        try:
            with self.admin_db_engine.connect() as conn:
                table_comment = conn.execute(table_comment_query).scalar_one_or_none()
                cols = conn.execute(query, {"table_name": table_name}).fetchall()
            schema_str = f"-- Description de la table '{table_name}': {table_comment}\nCREATE TABLE {table_name} (\n"
            for col in cols:
                col_name, data_type, description = col
                line = f"    {col_name} {data_type}"
                if description:
                    line += f" -- {description}"
                schema_str += line + ",\n"
            schema_str = schema_str.rstrip(",\n") + "\n);"
            return schema_str
        except Exception as e:
            logger.error("Impossible de r√©cup√©rer le sch√©ma pour %s: %s", table_name, e)
            return f"CREATE TABLE {table_name} (...); -- Erreur r√©cup√©ration sch√©ma: {e}"

    # ------------------------ SQL validation & execution ------------------------
    def _extract_sql_from_text(self, text: str) -> str:
        """Extrait le SQL depuis la r√©ponse du LLM, en priorit√© depuis les balises <sql>."""
        if not text:
            return ""
        
        # 1. Priorit√© aux balises <sql>...</sql> (Chain of Thought format)
        sql_tag = re.search(r"<sql>([\s\S]*?)</sql>", text, flags=re.IGNORECASE)
        if sql_tag:
            candidate = sql_tag.group(1).strip()
            # Nettoyer les √©ventuels blocs markdown √† l'int√©rieur
            candidate = re.sub(r"```(?:sql)?\s*", "", candidate)
            candidate = re.sub(r"```", "", candidate)
            return candidate.strip()
        
        # 2. Blocs de code markdown ```sql ... ```
        code_block = re.search(r"```(?:sql)?\s*([\s\S]*?)```", text, flags=re.IGNORECASE)
        if code_block:
            candidate = code_block.group(1).strip()
            return candidate
        
        # 3. Fallback : chercher SELECT ou WITH directement
        m = re.search(r"\b(SELECT|WITH)\b[\s\S]*", text, flags=re.IGNORECASE)
        if m:
            candidate = text[m.start():]
            semi = candidate.find(';')
            if semi != -1:
                candidate = candidate[:semi+1]
            return candidate.strip()
        
        return text.strip()

    def _extract_reasoning_from_text(self, text: str) -> str:
        """Extrait le raisonnement depuis les balises <raisonnement>."""
        if not text:
            return ""
        reasoning_tag = re.search(r"<raisonnement>([\s\S]*?)</raisonnement>", text, flags=re.IGNORECASE)
        if reasoning_tag:
            return reasoning_tag.group(1).strip()
        return ""

    def _validate_sql(self, sql_query: str) -> bool:
        try:
            banned = re.compile(r"\b(INSERT|UPDATE|DELETE|DROP|ALTER|CREATE|TRUNCATE|GRANT|REVOKE|MERGE|CALL|COPY|VACUUM|ANALYZE|EXPLAIN)\b", re.IGNORECASE)
            if banned.search(sql_query):
                logger.warning("Validation √©chou√©e : mot-cl√© non autoris√© d√©tect√©.")
                return False
            exprs = sqlglot.parse(sql_query, read="postgres")
            if not exprs or len(exprs) != 1:
                logger.warning("Validation √©chou√©e : aucune ou plusieurs instructions d√©tect√©es.")
                return False
            expr = exprs[0]
            if isinstance(expr, sqlglot.exp.With):
                base_expr = expr.this
            else:
                base_expr = expr
            allowed = (sqlglot.exp.Select, sqlglot.exp.Union, sqlglot.exp.Except, sqlglot.exp.Intersect)
            if not isinstance(base_expr, allowed):
                logger.warning("Validation √©chou√©e : expression non autoris√©e.")
                return False
            return True
        except Exception as e:
            logger.error("Erreur validation SQL: %s", e)
            return False

    async def _execute_sql_readonly(self, sql: str) -> List[Dict[str, Any]]:
        def run():
            with self.db_engine.connect() as connection:
                result_proxy = connection.execute(text(sql))
                return [dict(row._mapping) for row in result_proxy]
        try:
            return await asyncio.to_thread(run)
        except exc.SQLAlchemyError as e:
            logger.error("Erreur ex√©cution SQL: %s", e)
            raise

    # ------------------------ Forecasting & inflation interpretation -----------
    async def format_inflation_prediction(self, prediction_data: dict) -> dict:
            """
            Formate les donn√©es de pr√©diction d'inflation re√ßues du mod√®le externe selon le sch√©ma InflationPredictionResponse.
            
            Args:
                prediction_data: Dictionnaire contenant les pr√©dictions d'inflation brutes du mod√®le
                
            Returns:
                Dictionnaire format√© selon InflationPredictionResponse
            """
            try:
                # Validation et formatage sp√©cifique aux pr√©dictions d'inflation
                formatted_response = {
                    "predictions": prediction_data.get("predictions", {}),
                    "global_shap_importance": prediction_data.get("global_shap_importance", {}),
                    "shap_summary_details": prediction_data.get("shap_summary_details", {}),
                    "individual_shap_explanations": prediction_data.get("individual_shap_explanations", {}),
                    "confidence_intervals": prediction_data.get("confidence_intervals", None)
                }
                
                # Validation des donn√©es d'inflation
                self._validate_inflation_data(formatted_response)
                
                return formatted_response
                
            except Exception as e:
                logger.error(f"Erreur lors du formatage de la pr√©diction d'inflation : {e}")
                raise

    async def generate_inflation_interpretation(self, body, timeout: int = 120) -> dict:
        """
        G√©n√®re une interpr√©tation √©conomique sp√©cialis√©e des pr√©dictions d'inflation SHAP 
        pour les √©conomistes et analystes de la BCEAO.
        
        Args:
            body: InflationInterpretationRequest contenant les donn√©es de pr√©diction et param√®tres
            timeout: Timeout en secondes pour l'appel LLM (par d√©faut 120)
            
        Returns:
            Dictionnaire contenant l'interpr√©tation √©conomique format√©e sp√©cifique √† l'inflation
        """
        try:
            # Extraction des donn√©es de pr√©diction d'inflation
            prediction_data = body.prediction_data
            audience = body.target_audience
            include_policy_recs = body.include_policy_recommendations
            include_monetary_analysis = body.include_monetary_policy_analysis
            focus_bceao = body.focus_on_bceao_mandate
            print(prediction_data)
            # Construction du prompt d'interpr√©tation sp√©cifique √† l'inflation
            interpretation_prompt = self._build_inflation_interpretation_prompt(
                prediction_data, audience, include_monetary_analysis, focus_bceao
            )
            
            # =======================================================================================
            # LANGCHAIN CHATOLLAMA - Inflation interpretation generation
            # =======================================================================================
            # G√©n√©ration de l'interpr√©tation via LLM
            async with self.llm_sem:
                response = await asyncio.wait_for(
                    self.llm.ainvoke(interpretation_prompt),
                    timeout=timeout
                )
            
            # Extract content from AIMessage
            interpretation_text = response.content.strip()
            
            # Parsing et structuration de la r√©ponse sp√©cifique √† l'inflation
            structured_interpretation = self._parse_inflation_interpretation(
                interpretation_text, include_policy_recs
            )
            
            return structured_interpretation
            
        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration de l'interpr√©tation d'inflation : {e}")
            raise
    
    def _validate_inflation_data(self, prediction_data) -> Dict[str, Any]:
        """
        Valide que les donn√©es de pr√©diction d'inflation sont coh√©rentes.
        Inclut des validations de s√©rie temporelle.
        
        Returns:
            Dict contenant les r√©sultats de validation et les warnings
        """
        validation_result = {
            "is_valid": True,
            "warnings": [],
            "errors": []
        }
        
        predictions = prediction_data.get("predictions", {})
        
        if not predictions:
            validation_result["errors"].append("Aucune pr√©diction fournie")
            validation_result["is_valid"] = False
            return validation_result
        
        # 1. V√©rifier que les valeurs d'inflation sont dans une plage raisonnable
        for period, value in predictions.items():
            if not isinstance(value, (int, float)):
                validation_result["errors"].append(f"Valeur d'inflation invalide pour {period}: {value}")
                validation_result["is_valid"] = False
            elif value < -10 or value > 50:  # Plage raisonnable pour l'inflation (%)
                validation_result["warnings"].append(f"Valeur d'inflation inhabituelle pour {period}: {value}%")
        
        # 2. Validation de s√©rie temporelle - Dates ordonn√©es et sans doublons
        dates = list(predictions.keys())
        if len(dates) != len(set(dates)):
            validation_result["warnings"].append("Dates en double d√©tect√©es dans les pr√©dictions")
        
        # Essayer de parser et trier les dates
        try:
            parsed_dates = []
            for date_str in dates:
                # Supporter plusieurs formats: YYYY-MM, YYYY-MM-DD, YYYY-Q1
                if "-Q" in date_str:
                    # Format trimestre: 2024-Q1 -> 2024-01
                    year, quarter = date_str.split("-Q")
                    month = (int(quarter) - 1) * 3 + 1
                    parsed_dates.append((date_str, datetime(int(year), month, 1)))
                elif len(date_str) == 7:  # YYYY-MM
                    parsed_dates.append((date_str, datetime.strptime(date_str, "%Y-%m")))
                elif len(date_str) == 10:  # YYYY-MM-DD
                    parsed_dates.append((date_str, datetime.strptime(date_str, "%Y-%m-%d")))
                else:
                    validation_result["warnings"].append(f"Format de date non reconnu: {date_str}")
            
            # V√©rifier l'ordre chronologique
            if parsed_dates:
                sorted_dates = sorted(parsed_dates, key=lambda x: x[1])
                original_order = [d[0] for d in parsed_dates]
                sorted_order = [d[0] for d in sorted_dates]
                if original_order != sorted_order:
                    validation_result["warnings"].append("Les dates ne sont pas en ordre chronologique")
                
                # V√©rifier les gaps (plus de 3 mois entre deux pr√©dictions)
                for i in range(1, len(sorted_dates)):
                    diff_days = (sorted_dates[i][1] - sorted_dates[i-1][1]).days
                    if diff_days > 95:  # ~3 mois
                        validation_result["warnings"].append(
                            f"Gap temporel important d√©tect√© entre {sorted_dates[i-1][0]} et {sorted_dates[i][0]}"
                        )
        except Exception as e:
            validation_result["warnings"].append(f"Impossible de valider l'ordre des dates: {str(e)}")
        
        # 3. V√©rifier la coh√©rence des variations (pas de sauts > 10 points)
        values = list(predictions.values())
        for i in range(1, len(values)):
            if abs(values[i] - values[i-1]) > 10:
                validation_result["warnings"].append(
                    f"Variation abrupte d'inflation d√©tect√©e: {values[i-1]:.2f}% ‚Üí {values[i]:.2f}%"
                )
        
        # 4. V√©rifier la pr√©sence des facteurs d'inflation typiques
        shap_importance = prediction_data.get("global_shap_importance", {})
        expected_factors = ["taux_change", "prix_petrole", "masse_monetaire", "alimentation"]
        
        missing_factors = []
        for factor in expected_factors:
            found = any(factor in key.lower() for key in shap_importance.keys())
            if not found:
                missing_factors.append(factor)
        
        if missing_factors:
            validation_result["warnings"].append(f"Facteurs d'inflation typiques non trouv√©s: {', '.join(missing_factors)}")
        
        # 5. V√©rifier que les SHAP individuels correspondent aux dates de pr√©diction
        individual_shap = prediction_data.get("individual_shap_explanations", {})
        if individual_shap:
            shap_dates = set(individual_shap.keys())
            pred_dates = set(predictions.keys())
            if shap_dates != pred_dates:
                missing_in_shap = pred_dates - shap_dates
                extra_in_shap = shap_dates - pred_dates
                if missing_in_shap:
                    validation_result["warnings"].append(f"SHAP manquants pour les dates: {missing_in_shap}")
                if extra_in_shap:
                    validation_result["warnings"].append(f"SHAP suppl√©mentaires non associ√©s: {extra_in_shap}")
        
        # Log des r√©sultats
        if validation_result["errors"]:
            for error in validation_result["errors"]:
                logger.error(f"Validation inflation: {error}")
        if validation_result["warnings"]:
            for warning in validation_result["warnings"]:
                logger.warning(f"Validation inflation: {warning}")
        
        return validation_result

    def _build_inflation_interpretation_prompt(self, prediction_data, audience, include_monetary_analysis, focus_bceao):
        """
        Construit le prompt sp√©cialis√© pour l'interpr√©tation des pr√©dictions d'inflation.
        """
        audience_descriptions = {
            "economist": {"fr": "√©conomiste sp√©cialis√© en politique mon√©taire", "en": "monetary policy economist"},
            "analyst": {"fr": "analyste inflation", "en": "inflation analyst"},
            "policymaker": {"fr": "d√©cideur de politique mon√©taire", "en": "monetary policymaker"},
            "general": {"fr": "public g√©n√©ral", "en": "general public"}
        }
        
        audience_desc = audience_descriptions[audience]
        institutional_line_fr = ""
        if focus_bceao:
            institutional_line_fr = "- Met en avant le mandat de stabilit√© des prix de la BCEAO et les obligations statutaires vis-√†-vis des √âtats membres."
            
        
        predictions = prediction_data.predictions
        if predictions:
            avg_inflation = sum(predictions.values()) / len(predictions)
            trend = "hausse" if list(predictions.values())[-1] > list(predictions.values())[0] else "baisse"
        else:
            avg_inflation = 0
            trend = "stable"

        # ==============================================================================
        # Traitement avanc√© des donn√©es SHAP pour justification
        # ==============================================================================
        
        # 1. Pr√©parer les SHAP individuels arrondis pour la lisibilit√©
        individual_shap = getattr(prediction_data, 'individual_shap_explanations', None) or {}
        individual_shap_rounded: dict = {}
        for d, feats in individual_shap.items():
            try:
                # Arrondir les valeurs pour all√©ger le prompt et faciliter la lecture par le LLM
                individual_shap_rounded[d] = {k: round(float(v), 6) for k, v in feats.items()}
            except (ValueError, TypeError):
                individual_shap_rounded[d] = feats # Garder tel quel en cas d'erreur

        # 2. Identifier les Top N contributeurs positifs et n√©gatifs par date
        TOP_N = 5
        top_contrib_by_date: dict = {}
        for d, feats in individual_shap_rounded.items():
            items = list(feats.items())
            # Trier pour trouver les contributeurs les plus forts (positifs et n√©gatifs)
            pos_sorted = [it for it in sorted(items, key=lambda x: x[1], reverse=True) if it[1] > 0]
            neg_sorted = [it for it in sorted(items, key=lambda x: x[1]) if it[1] < 0]
            top_contrib_by_date[d] = {
                "top_positive": pos_sorted[:TOP_N],
                "top_negative": neg_sorted[:TOP_N],
            }

        # 3. Lister toutes les features pr√©sentes pour √©viter l'hallucination de facteurs externes
        features_present = set()
        try:
            features_present.update((prediction_data.global_shap_importance or {}).keys())
        except Exception:
            pass
        for feats in individual_shap_rounded.values():
            features_present.update(feats.keys())
        features_present_list = sorted(list(features_present))

        # ==============================================================================
        # Instructions de granularit√© selon l'audience
        # ==============================================================================

        audience_instructions = {
                "analyst": (
                "- Niveau de d√©tail: interm√©diaire.\n"
                "- Pour chaque date, lister le top N positif/n√©gatif avec valeurs SHAP et courte justification.\n"
                "- Ajouter des liens entre facteurs et m√©canismes de transmission.\n"
            ),
            "economist": (
                "- Niveau de d√©tail: technique et complet.\n"
                "- Pour chaque date, expliquer chiffre par chiffre la pr√©vision et les contributions SHAP (valeur et signe).\n"
                "- D√©crire les interactions, effets de base/saisonnalit√© et persistance attendue.\n"
            ),
            "general": (
                "- Niveau de d√©tail: p√©dagogique et simplifi√©.\n"
                "- Expliquer avec des m√©taphores sobres, toujours en citant les chiffres saillants.\n"
            ),
        }[audience]

        # S√©rialiser les structures complexes pour une injection propre dans le prompt
        try:
            shap_individuals_str = json.dumps(individual_shap_rounded, ensure_ascii=False, indent=2)
            top_contrib_str = json.dumps(top_contrib_by_date, ensure_ascii=False, indent=2)
        except Exception:
            shap_individuals_str = str(individual_shap_rounded)
            top_contrib_str = str(top_contrib_by_date)

        # ==============================================================================
        # Construction du prompt enrichi
        # ==============================================================================
        
        prompt = f"""
                    R√¥le et Mission :
                    Tu es l'√©conomiste en chef de la BCEAO. Ta mission est d‚Äôanalyser les pr√©visions mensuelles d‚Äôinflation pour l‚ÄôUEMOA.

                    Objectif :
                    Fournir une analyse narrative claire, d√©taill√©e et rigoureusement justifi√©e des pr√©visions d‚Äôinflation pour {audience_desc}, **en utilisant uniquement les donn√©es fournies**.

                    Contexte :
                    - Mandat BCEAO : stabilit√© des prix, croissance √©conomique, solidit√© du syst√®me financier.
                    - Objectif d‚Äôinflation annuel : 1-3 %.

                    Donn√©es disponibles :
                    - Pr√©dictions mensuelles : {predictions}
                    - Contributions SHAP par mois : {shap_individuals_str}  
                    - Inflation moyenne : {avg_inflation:.2f}%
                    - Tendance g√©n√©rale : {trend}  
                    - Variables disponibles : {features_present_list}  
                    - Principaux facteurs : {top_contrib_str}

                    Instructions importantes :
                    1. **Toujours utiliser les valeurs fournies** sans les modifier et sans changer leur signe.
                    2. Remplacer syst√©matiquement les placeholders AAAA-MM par les dates exactes.
                    3. Explications mois par mois : indiquer date r√©elle, inflation pr√©vue, contributions SHAP et interpr√©tation (SHAP positif = inflationniste, SHAP n√©gatif = d√©sinflationniste).
                    4. Ne jamais utiliser de donn√©es externes ou inventer des chiffres.
                    5. Distinguer clairement l‚Äôinflation mensuelle pr√©vue et l‚Äôinflation annuelle cible BCEAO.
                    6. Signaler toute donn√©e manquante n√©cessaire √† une analyse compl√®te.

                    Structure recommand√©e de l‚Äôanalyse :
                    1. **R√©sum√© ex√©cutif** : message cl√©, tendances g√©n√©rales.
                    2. **√âvolution mensuelle** : analyse mois par mois avec valeurs exactes et contributions SHAP.
                    3. **Facteurs de l‚Äôinflation** : moteurs inflationnistes et d√©sinflationnistes, avec explications simples bas√©es sur les SHAP.
                    4. **Justification chiffr√©e** :
                    - Date r√©elle
                    - Inflation pr√©vue
                    - Liste des facteurs SHAP et impact
                    - Effet potentiel sur la trajectoire annuelle
                    5. **√âvaluation de la stabilit√© des prix** : comparaison de l‚Äôinflation moyenne avec l‚Äôobjectif BCEAO.
                    6. **Risques inflationnistes** : facteurs positifs et n√©gatifs, valeurs exactes.
                    7. **Limites et incertitudes** : bas√©es uniquement sur les variables fournies.
                    8. **Recommandations de politique mon√©taire** (optionnel) : justifi√©es par l‚Äôanalyse.

                    Rappel final :
                    - Utiliser uniquement les donn√©es fournies.
                    - Ne jamais changer le signe des valeurs.
                    - Expliquer clairement mois par mois, avec SHAP et inflation exacte.
                    - Suivre scrupuleusement cette structure.
                    - R√©diger en fran√ßais, sous forme de texte fluide, sans titres visibles et sans r√©p√©titions et tu dois utiliser un fran√ßais plus humain.
                    """

        return prompt

    def _parse_inflation_interpretation(self, interpretation_text, include_policy_recs):
        """
        Parse et structure la r√©ponse d'interpr√©tation d'inflation g√©n√©r√©e par le LLM.
        """
        # Initialisation avec des valeurs par d√©faut sp√©cifiques √† l'inflation
        parsed = {
            "executive_summary": "",
            "inflation_analysis": "",
            "key_inflation_drivers": [],
            "price_stability_assessment": "",
            "monetary_policy_recommendations": None,
            "inflation_risks": [],
            "model_confidence": "",
            "target_deviation_analysis": "",
            "external_factors_impact": ""
        }
        
        try:
            # D√©coupage par sections
            sections = re.split(r'####\s*', interpretation_text)
            
            for section in sections:
                section = section.strip()
                if not section:
                    continue
                    
                # Identification des sections sp√©cifiques √† l'inflation
                first_line = section.split('\n')[0].strip().lower()
                
                if any(keyword in first_line for keyword in ["r√©sum√©", "summary", "ex√©cutif", "executive"]):
                    parsed["executive_summary"] = self._extract_section_content(section)
                elif any(keyword in first_line for keyword in ["dynamiques", "dynamics"]) and "inflation" in first_line:
                    parsed["inflation_analysis"] = self._extract_section_content(section)
                elif any(keyword in first_line for keyword in ["moteurs", "drivers", "principaux", "key"]):
                    parsed["key_inflation_drivers"] = self._extract_list_items(section)
                elif any(keyword in first_line for keyword in ["stabilit√©", "stability", "prix", "price"]):
                    parsed["price_stability_assessment"] = self._extract_section_content(section)
                elif any(keyword in first_line for keyword in ["recommandations", "mon√©taire"]):
                    if include_policy_recs:
                        parsed["monetary_policy_recommendations"] = self._extract_section_content(section)
                elif any(keyword in first_line for keyword in ["risques", "risks"]) and "inflation" in first_line:
                    parsed["inflation_risks"] = self._extract_list_items(section)
                elif any(keyword in first_line for keyword in ["confiance", "fiabilit√©"]):
                    parsed["model_confidence"] = self._extract_section_content(section)
                elif any(keyword in first_line for keyword in ["externes", "facteurs"]):
                    parsed["external_factors_impact"] = self._extract_section_content(section)
                elif any(keyword in first_line for keyword in ["√©cart", "cible"]):
                    parsed["target_deviation_analysis"] = self._extract_section_content(section)
            
            # Si pas de recommandations demand√©es, on met None
            if not include_policy_recs:
                parsed["monetary_policy_recommendations"] = None
                
        except Exception as e:
            logger.error(f"Erreur lors du parsing de l'interpr√©tation d'inflation : {e}")
            # En cas d'erreur, on met tout le texte dans le r√©sum√© ex√©cutif
            parsed["executive_summary"] = interpretation_text[:500] + "..." if len(interpretation_text) > 500 else interpretation_text
        
        return parsed


    def _extract_section_content(self, section_text):
        """Extrait le contenu principal d'une section en supprimant le titre."""
        lines = section_text.split('\n')
        # Supprime la premi√®re ligne qui contient g√©n√©ralement le titre
        content_lines = lines[1:] if len(lines) > 1 else lines
        return '\n'.join(content_lines).strip()

    def _extract_list_items(self, section_text):
        """Extrait les √©l√©ments d'une liste √† partir d'une section."""
        items = []
        content = self._extract_section_content(section_text)
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            # D√©tecte les listes avec -, *, ‚Ä¢, ou num√©rot√©es
            if line and (line.startswith('-') or line.startswith('*') or line.startswith('‚Ä¢') or 
                        (len(line) > 2 and line[0].isdigit() and line[1] in ['.', ')'])):
                # Nettoie le marqueur de liste
                clean_item = re.sub(r'^[-*‚Ä¢]\s*|^\d+[.)]\s*', '', line).strip()
                if clean_item:
                    items.append(clean_item)
        
        # Si aucun item de liste n'est trouv√©, on retourne le contenu brut splitt√© par ligne
        if not items and content:
            return [l.strip() for l in content.split('\n') if l.strip()]

        print("Extracted list items:", items)
        return items
        
    # ------------------------ pull model ---------------------------------------
    async def pull_model(self, model: Optional[str] = None) -> Dict[str, Any]:
        target_model = model or settings.LLM_MODEL
        try:
            async with self.llm_sem:
                await asyncio.wait_for(self.ollama_client.pull(model=target_model), timeout=600)
            return {"status": "success", "model": target_model}
        except Exception as e:
            logger.error("Erreur pull model: %s", e)
            return {"status": "error", "message": str(e), "model": target_model}

    # ------------------------ Heuristics / routing --------------------------------
    def _init_keyword_sets(self) -> None:
        base_economic_keywords = {
            "uemoa", "bceao", "union √©conomique", "union mon√©taire",
            "pib", "produit int√©rieur brut", "croissance √©conomique",
            "inflation", "d√©flation", "prix", "ipc", "indice prix",
            "taux", "taux d'int√©r√™t", "taux directeur", "politique mon√©taire",
            "dette", "dette publique", "encours dette", "dette pib",
            "recettes fiscales", "d√©penses publiques", "budget", "solde budg√©taire",
            "importations", "exportations", "balance commerciale", "biens fob",
            "r√©serves", "r√©serves internationales", "change", "devise",
            "masse mon√©taire", "m2", "m3", "liquidit√© bancaire",
            "investissement", "consommation", "√©pargne", "transferts",
            "diaspora", "migrants", "transferts migrants",
            "agriculture", "industrie", "services", "secteurs",
            "emploi", "ch√¥mage", "population active",
            "fcfa", "franc cfa", "zone franc", "euro",
            "indicateurs √©conomiques", "statistiques", "donn√©es √©conomiques",
            "contribution", "valeur ajout√©e"
        }
        
        sql_keywords = {"select", "where", "group by", "order by", "sql"}
        date_keywords = {"date", "ann√©e", "mois", "trimestre", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021", "2022", "2023", "2024", "2025"}
        dynamic_keywords = set()
        try:
            with self.admin_db_engine.connect() as conn:
                rows = conn.execute(text("SELECT column_name FROM information_schema.columns WHERE table_name = :table"), {"table": self.db_tables[0]}).fetchall()
            for (col,) in rows:
                dynamic_keywords.add(col.lower())
        except Exception:
            pass
        self.economic_keywords = base_economic_keywords | dynamic_keywords
        self.sql_keywords = sql_keywords
        self.date_keywords = date_keywords

    def _is_question_harmful(self, text_q: str) -> bool:
        if not text_q:
            return False
        q = text_q.lower()
        banned_terms = [
             # Violence / armes
            "bombe", "explosif", "fabrication d'arme", "arme artisanale", "arme", "pistolet", "fusil",
            "grenade", "cocktail molotov", "mitraillette", "kalachnikov", "munitions", "couteau", "assassin",
            "meurtre", "tuer", "massacre", "terrorisme", "attentat", "prise d'otage", "violence",

            # Cybercriminalit√©
            "piratage", "hacker", "pirater", "craquer", "intrusion", "malware", "ransomware", 
            "phishing", "cheval de troie", "virus informatique", "backdoor", "attaque ddos",
            "keylogger", "spyware",

            # Drogues / substances
            "drogue", "stup√©fiant", "cannabis", "coca√Øne", "h√©ro√Øne", "ecstasy", "lsd", "meth", 
            "opium", "poison", "toxicomanie",

            # Escroquerie / arnaque
            "arnaque", "escroquerie", "fraude", "blanchiment", "usurpation d'identit√©",

            # Contenus sensibles
            "sexe", "pornographie", "p√©dophilie", "inceste", "viol", "prostitution"
        ]
        return any(term in q for term in banned_terms)

    def _needs_data_retrieval(self, text_q: str, has_history: bool = False) -> bool:
        """
        Heuristique stricte pour d√©cider si la question concerne UNIQUEMENT les donn√©es √©conomiques UEMOA/BCEAO.
        Refuse les questions g√©n√©rales, hors-sujet, ou trop vagues.
        Si has_history est True, on est plus tol√©rant (questions de suivi).
        """
        if not text_q or len(text_q.strip()) < 2:  # Questions vides ou trop courtes
            return False

        q = text_q.lower().strip()

        # Si on a un historique, on accepte les questions courtes de suivi (ex: "Et en 2024 ?")
        if has_history:
            # On v√©rifie juste qu'il y a un minimum de contenu pertinent (date ou mot cl√© ou juste une phrase)
            # Pour l'instant, on accepte presque tout si ce n'est pas vide, car le contexte peut donner du sens √† tout.
            return True

        if len(text_q.strip()) < 5:
            return False

        economic_count = sum(1 for kw in self.economic_keywords if kw in q)
        sql_count = sum(1 for kw in self.sql_keywords if kw in q)
        date_count = sum(1 for kw in self.date_keywords if kw in q)

        # Crit√®res stricts pour accepter la question :
        # - Au moins 2 mots-cl√©s √©conomiques
        #   OU (1 mot-cl√© √©conomique + r√©f√©rence temporelle)
        #   OU (1 mot-cl√© √©conomique + intention SQL explicite)
        has_economic_focus = (
            economic_count >= 2
            or (economic_count >= 1 and date_count >= 1)
            or (economic_count >= 1 and sql_count >= 1)
        )
        has_temporal_reference = date_count >= 1 or sql_count >= 1

        return has_economic_focus and has_temporal_reference
